{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytxq2iYLkVCR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup, element\n",
        "import json\n",
        "import re\n",
        "\n",
        "base_url = 'https://www.mayoclinic.org/'\n",
        "\n",
        "diseaselinks = []\n",
        "secondpage = []\n",
        "range = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','R','S','T','U','V','W','X','Y','Z','#']\n",
        "for x in range:\n",
        "  r = requests.get(f'https://www.mayoclinic.org/diseases-conditions/index?letter={x}')\n",
        "  soup = BeautifulSoup(r.content, 'lxml')\n",
        "  name = soup.get_text('h1')\n",
        "  diseaselist = soup.find_all('div', class_ = 'cmp-result-name')\n",
        "\n",
        "  for item in diseaselist:\n",
        "      #print(item)\n",
        "      #dlink = item['href']\n",
        "      for link in item.find_all('a', href = True):\n",
        "        diseaselinks.append(link['href'])\n",
        "        #print(diseaselinks)\n",
        "\n",
        "        a,b,c,d,e = \"\",\"\",\"\",\"\",\"\"\n",
        "\n",
        "      for link in diseaselinks:\n",
        "          r =  requests.get(link)\n",
        "          soup = BeautifulSoup(r.content, 'lxml')\n",
        "          name = soup.find('h1').text.strip()\n",
        "          details = soup.find_all('div', class_ = False)\n",
        "\n",
        "          for item in details:\n",
        "            symptoms_tag = soup.find('h2', string='Symptoms')\n",
        "            if symptoms_tag:\n",
        "              a_ul_tag = symptoms_tag.find_next('ul')\n",
        "              a = [tag.get_text(strip=True) for tag in a_ul_tag.find_all('li')]\n",
        "\n",
        "            # Find the h2 tag with text \"Causes\"\n",
        "            causes_tag = soup.find('h2', string='Causes')\n",
        "            if causes_tag:\n",
        "              b_ul_tag = causes_tag.find_next('ul')\n",
        "              b = [tag.get_text(strip=True) for tag in b_ul_tag.find_all('li')]\n",
        "\n",
        "            # Find the h2 tag with text \"Risk Factors\"\n",
        "            risk_factors_tag = soup.find('h2', string='Risk factors')\n",
        "            if risk_factors_tag:\n",
        "              c_ul_tag = risk_factors_tag.find_next('ul')\n",
        "              c = [tag.get_text(strip=True) for tag in c_ul_tag.find_all('li')]\n",
        "\n",
        "            # Find the h2 tag with text \"Complications\"\n",
        "            complications_tag = soup.find('h2', string='Complications')\n",
        "            if complications_tag:\n",
        "              d_ul_tag = complications_tag.find_next('ul')\n",
        "              d = [tag.get_text(strip=True) for tag in d_ul_tag.find_all('li')]\n",
        "\n",
        "            # Find the h2 tag with text \"Prevention\"\n",
        "            prevention_tag = soup.find('h2', string='Prevention')\n",
        "            if prevention_tag:\n",
        "              e_ul_tag = prevention_tag.find_next('ul')\n",
        "              e = [tag.get_text(strip=True) for tag in e_ul_tag.find_all('li')]\n",
        "\n",
        "\n",
        "          detailslist = {\n",
        "                  'link': link,\n",
        "                  'name': name,\n",
        "                  'Symptoms': a,\n",
        "                  'Causes': b,\n",
        "                  'Risk Factors': c,\n",
        "                  'Complications': d,\n",
        "                  'Prevention': e,\n",
        "                  }\n",
        "\n",
        "      print(link, name, len(a), len(b), len(c), len(d), len(e))\n",
        "      with open(f'/content/drive/MyDrive/Colab Notebooks/{x}.json', 'a') as f:\n",
        "        json.dump(detailslist, f, indent=8, ensure_ascii=False)\n",
        "        print(\"Created Json File\")"
      ]
    }
  ]
}